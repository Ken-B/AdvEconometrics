{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# copy of GLS from case 1 to easier combine files later and have consistent notation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "type ols_results\n",
    "  coefs \n",
    "  yhat\n",
    "  res\n",
    "  vcv\n",
    "  tstat\n",
    "  pval\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Int(floor(3.1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "gls (generic function with 1 method)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# keyword arguments are placed after semicolon\n",
    "function gls(y, X; corr=:none, lags=nothing)\n",
    "    \n",
    "    # more stable: β̂ = X \\ y, see notes at bottom\n",
    "    β̂ = inv(X' * X) * (X' * y)\n",
    "    ŷ = X * β̂\n",
    "    μ̂ = y - ŷ\n",
    "    \n",
    "    T, K = size(X)\n",
    "    σ̂² = dot(μ̂, μ̂) / (T - K)\n",
    "\n",
    "    #use correction for variance covariance\n",
    "    if corr == :none\n",
    "        vcv = σ̂² * inv(X' * X)\n",
    "        \n",
    "    elseif corr == :white\n",
    "        # or do newey_west with lags=0\n",
    "        vcv = inv(X' * X) * X' * diagm(μ̂.^2) * X * inv(X' * X)\n",
    "        \n",
    "    elseif corr == :newey_west\n",
    "        if lags == nothing \n",
    "            lags = Int(floor(T^(1/4)))\n",
    "        end\n",
    "        vcv = newey_west(X, μ̂, lags)\n",
    "    else\n",
    "        error(\"\")\n",
    "    end\n",
    "\n",
    "    # T statistics for H₀: β₀ = 0\n",
    "    tstat = β̂ ./ sqrt(diag(vcv))\n",
    "    \n",
    "    # absolute value and times two for double sided test\n",
    "    pval  = 2 * ccdf(TDist(T-K), abs(tstat)) \n",
    "\n",
    "    return ols_results(β̂, ŷ, μ̂, vcv, tstat, pval)\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Strict set of GM assumptions:\n",
    "* X is deterministic, x is thus fixed over repeated samples\n",
    "* errors $\\mu$ are normally distributed with assumed homoscedastic errors\n",
    "\n",
    "Give the small sample and asymptotic properties of the OLS estimator for $\\beta$ and for the estimator of the standard errors.\n",
    "\n",
    "Small sample properties:\n",
    "* best unbiased estimator\n",
    "* estimator is normally distributed (stems from the fact that $\\hat{\\beta}$ is linear function of disturbance vector $\\mu$)\n",
    "* covariance matrix $\\sigma^2(X'X)^{-1}$ with an unbiased estimator of $\\sigma^2$ given by\n",
    "\n",
    "$$\\hat{\\sigma}^2 = \\frac{\\hat{\\mu}'\\hat{\\mu}}{N-K} = \\frac{y'My}{N-K}$$\n",
    "\n",
    "\n",
    "Asymptotic properties:\n",
    "* same under the GM conditions\n",
    "* $\\bar{x}_N$ assymptotically approaches $N(\\mu,\\frac{\\sigma^2}{N})$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "using Distributions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setting up a monte carlo simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "β₀ = 10\n",
    "β₁ = 1\n",
    "β = [β₀, β₁]\n",
    "σ² = 1\n",
    "sample_size = 100\n",
    "runs = 100000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Model to generate Y\n",
    "y(X,β,μ) = X * β + μ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 1: specify a population = N(5,2) draw sample once to have a deterministic sample, sample errors R times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "gen_X(sample_size) = hcat(ones(sample_size), rand(Normal(5, 2), sample_size))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "gen_μ(sample_size) = randn(sample_size,1)*sqrt(σ²)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "a = [1,2,3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "zeros(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "function MC_simple_OLS_numeric!(β, sample_size, runs, σ²)\n",
    "    β̂̄_MC = zeros(β) #it is beta-hat-bar\n",
    "    se_β̂̄_MC = zeros(β)\n",
    "    X = gen_X(sample_size) #deterministic\n",
    "    TrueSE = diag(σ²*inv(X'*X))\n",
    "    for MC_run = 1:runs\n",
    "        μ = gen_μ(sample_size)\n",
    "        y_model = y(X,β,μ)\n",
    "        gls_results = gls(y_model,X)\n",
    "        β̂̄_MC += gls_results.coefs\n",
    "        se_β̂̄_MC += diag(gls_results.vcv) #I THINK THIS GIVES THE MEAN OF THE SE OF $\\hat{\\beta}$\n",
    "    end\n",
    "    β̂̄_MC /= runs\n",
    "    se_β̂̄_MC /= runs\n",
    "    return β, TrueSE, β̂̄_MC, se_β̂̄_MC\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "MC_simple_OLS_numeric!(β, sample_size, runs, σ²)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "step 2: calculate statistics and save them (ols estimator, estimated ols standard error, t-statistic)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that std does not use the standard formulation of standard deviation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "this gives the true standard error of the total simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "std_of_x(x) = norm(x - mean(x))/sqrt(length(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "t_test(vec,H₀) = (mean(vec) - H₀)/std(vec)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "part 2: lagged dependent variable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Introducing lagged dependent variables makes it so that the assumption \"X and $\\mu$ are independent\" has to be relaxed to $E[\\mu_t|x_t] = 0$ or thus that the errors are contemporaneously independent with any explanatory variables.\n",
    "\n",
    "The OLS estimator becomes:\n",
    "* Biased: $E[\\hat{\\beta}|X] = \\beta + (X'X)^{-1}X'E[\\mu|X]$ => $E[\\hat{\\beta}] = E_X(E[\\hat{\\beta}|X]) \\neq \\beta$\n",
    "* Consistent and asymptotically normally distributed: $plim\\hat{\\beta} = \\beta + plim \\frac{X'X}{T}^{-1} plim\\frac{X'\\mu}{T}$ = 0 because $plim\\frac{X'\\mu}{T} = E(x_t\\mu_t) = 0$\n",
    "* $\\hat{\\sigma}^2 = \\frac{\\hat{\\mu}'\\hat{\\mu}}{T-k}$ is still a consistent estimator for $\\sigma^2$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100000"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "β₀ = 10\n",
    "β₁ = 0\n",
    "β = [β₀, β₁]\n",
    "σ² = 1\n",
    "#sample_size = 100\n",
    "runs = 100000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "gen_lagged_y! (generic function with 1 method)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function gen_lagged_y!(β, sample_size)\n",
    "    y_t = zeros(sample_size)\n",
    "    y_t_min_1 = zeros(sample_size)\n",
    "    β₀, β₁ = β\n",
    "    y₀ = rand(Normal(β₀/(1-β₁), sqrt(σ²/(1-β₁^2)))) #keep fixed throughout sample sizes and drop from results\n",
    "    μ = randn()*sqrt(σ²)\n",
    "    y_t_min_1[1] = y₀\n",
    "    y_t[1] = β₀ + β₁*y₀ + μ\n",
    "    for t = 2:length(y_t)\n",
    "        y_t_min_1[t] = y_t[t-1]\n",
    "        μ = randn()*sqrt(σ²)\n",
    "        y_t[t] = β₀ + β₁*y_t[t-1] + μ\n",
    "    end\n",
    "    return y_t, y_t_min_1\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "gen_lagged_y!(β, sample_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MC_LDV_OLS_numeric! (generic function with 1 method)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function MC_LDV_OLS_numeric!(β, sample_size, runs, σ²)\n",
    "    β̂̄_MC = zeros(β) #it is beta-hat-bar\n",
    "    se_β̂̄_MC = zeros(β)\n",
    "    TrueSE = zeros(β)\n",
    "    for MC_run = 1:runs\n",
    "        y_t, y_t_min_1 = gen_lagged_y!(β, sample_size)\n",
    "        X = hcat(ones(sample_size), y_t_min_1)\n",
    "        TrueSE += diag(σ²*inv(X'*X))\n",
    "        gls_results = gls(y_t,X)\n",
    "        β̂̄_MC += gls_results.coefs\n",
    "        se_β̂̄_MC += diag(gls_results.vcv) #I THINK THIS GIVES THE MEAN OF THE SE OF $\\hat{\\beta}$\n",
    "    end\n",
    "    β̂̄_MC /= runs\n",
    "    se_β̂̄_MC /= runs\n",
    "    TrueSE /= runs\n",
    "    return β, TrueSE, β̂̄_MC, se_β̂̄_MC\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([10,0],[0.101315,0.00100316],[10.0094,-0.000951111],[0.101099,0.001001])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = MC_LDV_OLS_numeric!(β, 1000, runs, σ²)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "bias = zeros(length(sample_sizes),length(β))\n",
    "for i = 1:length(sample_sizes)\n",
    "    results = MC_LDV_OLS_numeric!(β, sample_sizes[i], runs, σ²)\n",
    "    bias[i,:] = (results[3] - results[1])'\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "find_bias! (generic function with 1 method)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function find_bias!(β, runs, σ²)\n",
    "    sample_sizes = vcat(collect(10:10:100), collect(200:100:1000), collect(2000:1000:10000))\n",
    "    bias = zeros(length(sample_sizes),length(β))\n",
    "    for i = 1:length(sample_sizes)\n",
    "        results = MC_LDV_OLS_numeric!(β, sample_sizes[i], runs, σ²)\n",
    "        bias[i,:] = (results[3] - results[1])'\n",
    "    end\n",
    "    return sample_sizes, bias\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "LoadError",
     "evalue": "InterruptException:",
     "output_type": "error",
     "traceback": [
      "InterruptException:",
      "",
      " in *(::Float64, ::Float64) at /Applications/Julia-0.5.app/Contents/Resources/julia/lib/julia/sys.dylib:?",
      " in gen_lagged_y!(::Array{Int64,1}, ::Int64) at ./In[6]:11",
      " in MC_LDV_OLS_numeric!(::Array{Int64,1}, ::Int64, ::Int64, ::Int64) at ./In[7]:6",
      " in find_bias!(::Array{Int64,1}, ::Int64, ::Int64) at ./In[10]:5"
     ]
    }
   ],
   "source": [
    "sample_sizes, bias = find_bias!(β, runs, σ²)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "how can we use the MC simulation results to correct the bias of the OLS estimator for $\\beta_1$?\n",
    "\n",
    "* repeatedly save abs(true parameter - simulated parameter) to find the mean and distribution of the bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "using Plots\n",
    "gr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plot(randn(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Julia 0.5.0",
   "language": "julia",
   "name": "julia-0.5"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "0.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
