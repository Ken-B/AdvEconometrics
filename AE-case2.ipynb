{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# copy of GLS from case 1 to easier combine files later and have consistent notation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "type ols_results\n",
    "  coefs \n",
    "  yhat\n",
    "  res\n",
    "  vcv\n",
    "  tstat\n",
    "  pval\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Int(floor(3.1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "gls (generic function with 1 method)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# keyword arguments are placed after semicolon\n",
    "function gls(y, X; corr=:none, lags=nothing)\n",
    "    \n",
    "    # more stable: β̂ = X \\ y, see notes at bottom\n",
    "    β̂ = inv(X' * X) * (X' * y)\n",
    "    ŷ = X * β̂\n",
    "    μ̂ = y - ŷ\n",
    "    \n",
    "    T, K = size(X)\n",
    "    σ̂² = dot(μ̂, μ̂) / (T - K)\n",
    "\n",
    "    #use correction for variance covariance\n",
    "    if corr == :none\n",
    "        vcv = σ̂² * inv(X' * X)\n",
    "        \n",
    "    elseif corr == :white\n",
    "        # or do newey_west with lags=0\n",
    "        vcv = inv(X' * X) * X' * diagm(μ̂.^2) * X * inv(X' * X)\n",
    "        \n",
    "    elseif corr == :newey_west\n",
    "        if lags == nothing \n",
    "            lags = Int(floor(T^(1/4)))\n",
    "        end\n",
    "        vcv = newey_west(X, μ̂, lags)\n",
    "    else\n",
    "        error(\"\")\n",
    "    end\n",
    "\n",
    "    # T statistics for H₀: β₀ = 0\n",
    "    tstat = β̂ ./ sqrt(diag(vcv))\n",
    "    \n",
    "    # absolute value and times two for double sided test\n",
    "    pval  = 2 * ccdf(TDist(T-K), abs(tstat)) \n",
    "\n",
    "    return ols_results(β̂, ŷ, μ̂, vcv, tstat, pval)\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Strict set of GM assumptions:\n",
    "* X is deterministic, x is thus fixed over repeated samples\n",
    "* errors $\\mu$ are normally distributed with assumed homoscedastic errors\n",
    "\n",
    "Give the small sample and asymptotic properties of the OLS estimator for $\\beta$ and for the estimator of the standard errors.\n",
    "\n",
    "Small sample properties:\n",
    "* best unbiased estimator\n",
    "* estimator is normally distributed (stems from the fact that $\\hat{\\beta}$ is linear function of disturbance vector $\\mu$)\n",
    "* covariance matrix $\\sigma^2(X'X)^{-1}$ with an unbiased estimator of $\\sigma^2$ given by\n",
    "\n",
    "$$\\hat{\\sigma}^2 = \\frac{\\hat{\\mu}'\\hat{\\mu}}{N-K} = \\frac{y'My}{N-K}$$\n",
    "\n",
    "\n",
    "Asymptotic properties:\n",
    "* same under the GM conditions\n",
    "* $\\bar{x}_N$ assymptotically approaches $N(\\mu,\\frac{\\sigma^2}{N})$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "using Distributions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setting up a monte carlo simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100000"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "β₀ = 10\n",
    "β₁ = 1\n",
    "β = [β₀, β₁]\n",
    "σ² = 1\n",
    "sample_size = 25\n",
    "R = 100000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "y (generic function with 1 method)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Model to generate Y\n",
    "y(X,β,μ) = X * β + μ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 1: specify a population = N(5,2) draw sample once to have a deterministic sample, sample errors R times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "gen_X (generic function with 1 method)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gen_X(sample_size) = hcat(ones(sample_size), rand(Normal(5, 2), sample_size))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "gen_μ (generic function with 1 method)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gen_μ(sample_size) = randn(sample_size,1)*sqrt(σ²)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MC_numeric! (generic function with 1 method)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function MC_numeric!(β, sample_size)\n",
    "    β̂̄_MC = zeros(length(β)) #it is beta-hat-bar\n",
    "    se_β̂̄ = 0\n",
    "    X = gen_X(sample_size) #deterministic\n",
    "    for MC_run = 1:R\n",
    "        μ = gen_μ(sample_size)\n",
    "        σ² = dot(μ, μ) / (T - K) #DO THEY MEAN THIS BY TRUE STANDARD ERRORS?\n",
    "        y_model = y(X,β,μ)\n",
    "        gls_results = gls(y_model,X)\n",
    "        β̂̄_MC = β̂̄_MC + gls_results.coefs/R\n",
    "        se_β̂̄ = se_β̂̄ + sqrt(diag(gls_results.vcv))/R #I THINK THIS GIVES THE MEAN OF THE SE OF $\\hat{\\beta}$\n",
    "    end\n",
    "    return β̂̄_MC, se_β̂̄\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "LoadError",
     "evalue": "UndefVarError: T not defined",
     "output_type": "error",
     "traceback": [
      "UndefVarError: T not defined",
      "",
      " in MC_numeric!(::Array{Int64,1}, ::Int64) at ./In[9]:7"
     ]
    }
   ],
   "source": [
    "MC_numeric!(β, sample_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "step 2: calculate statistics and save them (ols estimator, estimated ols standard error, t-statistic)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that std does not use the standard formulation of standard deviation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "this gives the true standard error of the total simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "std_of_x (generic function with 1 method)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "std_of_x(x) = norm(x - mean(x))/sqrt(length(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "t_test (generic function with 1 method)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t_test(vec,H₀) = (mean(vec) - H₀)/std(vec)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "part 2: lagged dependent variable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Introducing lagged dependent variables makes it so that the assumption \"X and $\\mu$ are independent\" has to be relaxed to $E[\\mu_t|x_t] = 0$ or thus that the errors are contemporaneously independent with any explanatory variables.\n",
    "\n",
    "The OLS estimator becomes:\n",
    "* Biased: $E[\\hat{\\beta}|X] = \\beta + (X'X)^{-1}X'E[\\mu|X]$ => $E[\\hat{\\beta}] = E_X(E[\\hat{\\beta}|X]) \\neq \\beta$\n",
    "* Consistent and asymptotically normally distributed: $plim\\hat{\\beta} = \\beta + plim \\frac{X'X}{T}^{-1} plim\\frac{X'\\mu}{T}$ = 0 because $plim\\frac{X'\\mu}{T} = E(x_t\\mu_t) = 0$\n",
    "* $\\hat{\\sigma}^2 = \\frac{\\hat{\\mu}'\\hat{\\mu}}{T-k}$ is still a consistent estimator for $\\sigma^2$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "β₀ = 10\n",
    "β₁ = 0\n",
    "σ² = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25×1 Array{Float64,2}:\n",
       " -0.792707\n",
       "  1.58236 \n",
       "  0.444177\n",
       " -0.749981\n",
       " -2.06984 \n",
       " -0.218239\n",
       "  0.611709\n",
       "  0.356565\n",
       "  0.97148 \n",
       " -1.17465 \n",
       "  0.13426 \n",
       "  1.0049  \n",
       "  1.43578 \n",
       " -1.72348 \n",
       "  1.74055 \n",
       "  0.664466\n",
       "  0.330747\n",
       " -0.796498\n",
       " -0.653582\n",
       " -0.757919\n",
       " -0.574783\n",
       " -0.680621\n",
       " -0.773876\n",
       "  1.35384 \n",
       "  1.29551 "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y₀ = rand(Normal(β₀/(1-β₁), sqrt(σ²/(1-β₁^2)))) #keep fixed throughout sample sizes and drop from results\n",
    "μ = randn(sample_size,1)*sqrt(σ²)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to generate a seed to kickstart the iterative time evolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "gen_lagged_y! (generic function with 1 method)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function gen_lagged_y!(y, β, y₀)\n",
    "    β₀, β₁ = β\n",
    "    \n",
    "    μ = randn()\n",
    "    y[1] = β₀ + β₁*y₀ + μ\n",
    "    \n",
    "    for t = 2:length(y)\n",
    "        μ = randn()\n",
    "        y[t] = β₀ + β₁*y[t-1] + μ\n",
    "    end\n",
    "    return y\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "case2 (generic function with 1 method)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function case2(sample_size, β, y₀)\n",
    "    y = zeros(sample_size)\n",
    "    return gen_lagged_y!(y, β,y₀)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25-element Array{Float64,1}:\n",
       "  21.0562\n",
       "  31.4288\n",
       "  39.5714\n",
       "  49.9146\n",
       "  59.8718\n",
       "  70.3924\n",
       "  81.294 \n",
       "  89.8788\n",
       " 100.065 \n",
       " 110.661 \n",
       " 121.103 \n",
       " 132.343 \n",
       " 143.775 \n",
       " 153.151 \n",
       " 163.34  \n",
       " 173.938 \n",
       " 184.196 \n",
       " 194.989 \n",
       " 206.925 \n",
       " 217.56  \n",
       " 228.851 \n",
       " 237.695 \n",
       " 246.768 \n",
       " 256.071 \n",
       " 265.603 "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "case2(sample_size,β,y₀)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "how can we use the MC simulation results to correct the bias of the OLS estimator for $\\beta_1$?\n",
    "\n",
    "* repeatedly save abs(true parameter - simulated parameter) to find the mean and distribution of the bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OLS_normal (generic function with 1 method)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "OLS_normal(y, X) = inv(X'X) * X'y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "LoadError",
     "evalue": "MethodError: no method matching *(::Array{Float64,2}, ::#y)\u001b[0m\nClosest candidates are:\n  *(::Any, ::Any, \u001b[1m\u001b[31m::Any\u001b[0m, \u001b[1m\u001b[31m::Any...\u001b[0m) at operators.jl:138\n  *{T<:Union{Complex{Float32},Complex{Float64},Float32,Float64},S}(::Union{Base.ReshapedArray{T<:Union{Complex{Float32},Complex{Float64},Float32,Float64},2,A<:DenseArray,MI<:Tuple{Vararg{Base.MultiplicativeInverses.SignedMultiplicativeInverse{Int64},N}}},DenseArray{T<:Union{Complex{Float32},Complex{Float64},Float32,Float64},2},SubArray{T<:Union{Complex{Float32},Complex{Float64},Float32,Float64},2,A<:Union{Base.ReshapedArray{T,N,A<:DenseArray,MI<:Tuple{Vararg{Base.MultiplicativeInverses.SignedMultiplicativeInverse{Int64},N}}},DenseArray},I<:Tuple{Vararg{Union{Base.AbstractCartesianIndex,Colon,Int64,Range{Int64}},N}},L}}, \u001b[1m\u001b[31m::Union{Base.ReshapedArray{S,1,A<:DenseArray,MI<:Tuple{Vararg{Base.MultiplicativeInverses.SignedMultiplicativeInverse{Int64},N}}},DenseArray{S,1},SubArray{S,1,A<:Union{Base.ReshapedArray{T,N,A<:DenseArray,MI<:Tuple{Vararg{Base.MultiplicativeInverses.SignedMultiplicativeInverse{Int64},N}}},DenseArray},I<:Tuple{Vararg{Union{Base.AbstractCartesianIndex,Colon,Int64,Range{Int64}},N}},L}}\u001b[0m) at linalg/matmul.jl:79\n  *(::Union{Base.ReshapedArray{T,2,A<:DenseArray,MI<:Tuple{Vararg{Base.MultiplicativeInverses.SignedMultiplicativeInverse{Int64},N}}},DenseArray{T,2},SubArray{T,2,A<:Union{Base.ReshapedArray{T,N,A<:DenseArray,MI<:Tuple{Vararg{Base.MultiplicativeInverses.SignedMultiplicativeInverse{Int64},N}}},DenseArray},I<:Tuple{Vararg{Union{Base.AbstractCartesianIndex,Colon,Int64,Range{Int64}},N}},L}}, \u001b[1m\u001b[31m::Union{Base.LinAlg.QRCompactWYQ{S,M<:AbstractArray{T,2}},Base.LinAlg.QRPackedQ{T,S<:AbstractArray{T,2}}}\u001b[0m) at linalg/qr.jl:472\n  ...\u001b[0m",
     "output_type": "error",
     "traceback": [
      "MethodError: no method matching *(::Array{Float64,2}, ::#y)\u001b[0m\nClosest candidates are:\n  *(::Any, ::Any, \u001b[1m\u001b[31m::Any\u001b[0m, \u001b[1m\u001b[31m::Any...\u001b[0m) at operators.jl:138\n  *{T<:Union{Complex{Float32},Complex{Float64},Float32,Float64},S}(::Union{Base.ReshapedArray{T<:Union{Complex{Float32},Complex{Float64},Float32,Float64},2,A<:DenseArray,MI<:Tuple{Vararg{Base.MultiplicativeInverses.SignedMultiplicativeInverse{Int64},N}}},DenseArray{T<:Union{Complex{Float32},Complex{Float64},Float32,Float64},2},SubArray{T<:Union{Complex{Float32},Complex{Float64},Float32,Float64},2,A<:Union{Base.ReshapedArray{T,N,A<:DenseArray,MI<:Tuple{Vararg{Base.MultiplicativeInverses.SignedMultiplicativeInverse{Int64},N}}},DenseArray},I<:Tuple{Vararg{Union{Base.AbstractCartesianIndex,Colon,Int64,Range{Int64}},N}},L}}, \u001b[1m\u001b[31m::Union{Base.ReshapedArray{S,1,A<:DenseArray,MI<:Tuple{Vararg{Base.MultiplicativeInverses.SignedMultiplicativeInverse{Int64},N}}},DenseArray{S,1},SubArray{S,1,A<:Union{Base.ReshapedArray{T,N,A<:DenseArray,MI<:Tuple{Vararg{Base.MultiplicativeInverses.SignedMultiplicativeInverse{Int64},N}}},DenseArray},I<:Tuple{Vararg{Union{Base.AbstractCartesianIndex,Colon,Int64,Range{Int64}},N}},L}}\u001b[0m) at linalg/matmul.jl:79\n  *(::Union{Base.ReshapedArray{T,2,A<:DenseArray,MI<:Tuple{Vararg{Base.MultiplicativeInverses.SignedMultiplicativeInverse{Int64},N}}},DenseArray{T,2},SubArray{T,2,A<:Union{Base.ReshapedArray{T,N,A<:DenseArray,MI<:Tuple{Vararg{Base.MultiplicativeInverses.SignedMultiplicativeInverse{Int64},N}}},DenseArray},I<:Tuple{Vararg{Union{Base.AbstractCartesianIndex,Colon,Int64,Range{Int64}},N}},L}}, \u001b[1m\u001b[31m::Union{Base.LinAlg.QRCompactWYQ{S,M<:AbstractArray{T,2}},Base.LinAlg.QRPackedQ{T,S<:AbstractArray{T,2}}}\u001b[0m) at linalg/qr.jl:472\n  ...\u001b[0m",
      "",
      " in OLS_normal(::Function, ::Array{Float64,2}) at ./In[18]:1"
     ]
    }
   ],
   "source": [
    "y_2 = case2(sample_size,β,y₀)\n",
    "X = zeros(sample_size)\n",
    "X[1] = y₀\n",
    "for t = 1:(length(X)-1)\n",
    "    X[t+1] = y_2[t]\n",
    "end\n",
    "β₁_sim = OLS_normal(y,hcat(ones(sample_size),X))[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Julia 0.5.0",
   "language": "julia",
   "name": "julia-0.5"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "0.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
